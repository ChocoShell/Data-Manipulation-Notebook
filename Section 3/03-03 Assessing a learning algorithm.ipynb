{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we evaluate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Closer look at KNN solutions\n",
    "\n",
    "![KNN](KNN.png)\n",
    "\n",
    "Increasing K does not mean we are more likely to overfit or get a graph that closely maps to the data. K=1 is the most overfit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we increase the dimensions in a parametric model ($ax^2 + bx + c$) we are more likely to overfit.\n",
    "\n",
    "Parametric Models let us extrapolate future points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric 1 RMS Error\n",
    "- Root Mean Square\n",
    "$$RMSE = \\sqrt{\\frac{\\sum{(Y_{test} - Y_{predict})^2}}{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Sample vs out of sample\n",
    "We train in out training set then look at the results against the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most if not all cases, out of sample error is always bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "- training data is usually 60% of the data.  Test is 40%\n",
    "- You can slice the data into many different chunks (5) and have different tests for each chunk.  (Test, Train, Train, Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll forward cross validation\n",
    "- With finance, training data must be behind testing data.\n",
    "- Instead, have 2 chunks of (test, train) in the chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric 2: correlation\n",
    "- Get the correlation of Ytest vs Ypredict on a scatterplot.\n",
    "- np.corrcoef() -1 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, almost all, as RMS increases, correlation decreases.  It is possible to have both increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "As dimensions increase, overfit increases for in sample error, same as out of sample but at one point as we increase the degrees of freedom, out of sample error increases.\n",
    "\n",
    "When in sample is increasing and out of sample is decreasing in accuracy, we are overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting occurs near the beginning in KNN as K increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What has better performance\n",
    "- Space for saving model: LinReg\n",
    "- compute time to train: KNN\n",
    "- compute time to query: LinReg\n",
    "- ease to add new data: KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
